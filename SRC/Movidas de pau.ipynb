{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a69d37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpau-ventr\u001b[0m (\u001b[33mgrup10\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:  cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Pau\\Desktop\\PycharmProjects\\xnap-project-matcad_grup_10\\SRC\\wandb\\run-20230530_191930-7yzioi6m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grup10/pytorch-demo/runs/7yzioi6m' target=\"_blank\">iconic-pine-239</a></strong> to <a href='https://wandb.ai/grup10/pytorch-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grup10/pytorch-demo' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grup10/pytorch-demo/runs/7yzioi6m' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo/runs/7yzioi6m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9ecb178e6d4c54aaefbeb6046310ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 00050 examples: 8.026\n",
      "Loss after 00100 examples: 8.010\n",
      "Loss after 00150 examples: 7.957\n",
      "Loss after 00200 examples: 7.943\n",
      "Loss after 00250 examples: 7.904\n",
      "Loss after 00300 examples: 7.875\n",
      "Loss after 00350 examples: 7.808\n",
      "Loss after 00400 examples: 7.777\n",
      "Loss after 00450 examples: 7.722\n",
      "Loss after 00500 examples: 7.702\n",
      "Loss after 00550 examples: 7.648\n",
      "Loss after 00600 examples: 7.570\n",
      "Loss after 00650 examples: 7.531\n",
      "Loss after 00700 examples: 7.444\n",
      "Loss after 00750 examples: 7.368\n",
      "Loss after 00800 examples: 7.333\n",
      "Loss after 00850 examples: 7.297\n",
      "Loss after 00900 examples: 7.165\n",
      "Loss after 00950 examples: 7.010\n",
      "Loss after 01000 examples: 6.923\n",
      "Loss after 01050 examples: 6.831\n",
      "Loss after 01100 examples: 6.886\n",
      "Loss after 01150 examples: 6.729\n",
      "Loss after 01200 examples: 6.596\n",
      "Loss after 01250 examples: 6.563\n",
      "Loss after 01300 examples: 6.427\n",
      "Loss after 01350 examples: 6.366\n",
      "Loss after 01400 examples: 6.182\n",
      "Loss after 01450 examples: 6.148\n",
      "Loss after 01500 examples: 6.003\n",
      "Loss after 01550 examples: 6.029\n",
      "Loss after 01600 examples: 5.986\n",
      "Loss after 01650 examples: 5.889\n",
      "Loss after 01700 examples: 5.799\n",
      "Loss after 01750 examples: 5.734\n",
      "Loss after 01800 examples: 5.710\n",
      "Loss after 01850 examples: 5.733\n",
      "Loss after 01900 examples: 5.661\n",
      "Loss after 01950 examples: 5.692\n",
      "Loss after 02000 examples: 5.465\n",
      "Loss after 02050 examples: 5.477\n",
      "Loss after 02100 examples: 5.388\n",
      "Loss after 02150 examples: 5.415\n",
      "Loss after 02200 examples: 5.312\n",
      "Loss after 02250 examples: 5.329\n",
      "Loss after 02300 examples: 5.218\n",
      "Loss after 02350 examples: 5.294\n",
      "Loss after 02400 examples: 5.163\n",
      "Loss after 02450 examples: 5.149\n",
      "Loss after 02500 examples: 5.249\n",
      "Loss after 02550 examples: 5.184\n",
      "Loss after 02600 examples: 5.240\n",
      "Loss after 02650 examples: 5.113\n",
      "Loss after 02700 examples: 5.192\n",
      "Loss after 02750 examples: 4.989\n",
      "Loss after 02800 examples: 4.977\n",
      "Loss after 02850 examples: 5.022\n",
      "Loss after 02900 examples: 5.027\n",
      "Loss after 02950 examples: 5.000\n",
      "Loss after 03000 examples: 5.008\n",
      "Loss after 03050 examples: 4.994\n",
      "Loss after 03100 examples: 5.041\n",
      "Loss after 03150 examples: 4.929\n",
      "Loss after 03200 examples: 4.904\n",
      "Loss after 03250 examples: 4.894\n",
      "Loss after 03300 examples: 4.957\n",
      "Loss after 03350 examples: 4.705\n",
      "Loss after 03400 examples: 4.969\n",
      "Loss after 03450 examples: 4.996\n",
      "Loss after 03500 examples: 4.742\n",
      "Loss after 03550 examples: 4.740\n",
      "Loss after 03600 examples: 4.879\n",
      "Loss after 03650 examples: 4.843\n",
      "Loss after 03700 examples: 4.818\n",
      "Loss after 03750 examples: 4.803\n",
      "Loss after 03800 examples: 4.839\n",
      "Loss after 03850 examples: 4.673\n",
      "Loss after 03900 examples: 4.873\n",
      "Loss after 03950 examples: 4.795\n",
      "Loss after 04000 examples: 4.864\n",
      "Loss after 04045 examples: 4.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pau\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Pau\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Pau\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean BLEU score of the model on the 100 test images: 4.835781380720562e-155%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>████▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_mean_bleu</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>4.80721</td></tr><tr><td>test_mean_bleu</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">iconic-pine-239</strong> at: <a href='https://wandb.ai/grup10/pytorch-demo/runs/7yzioi6m' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo/runs/7yzioi6m</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230530_191930-7yzioi6m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from train import *\n",
    "from test import *\n",
    "from utils.utils import *\n",
    "from models.models import *\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "\n",
    "# Global variables\n",
    "global device\n",
    "\n",
    "import os\n",
    "\n",
    "# Setting CUDA ALLOC split size to 256 to avoid running out of memory\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "# Stopping wandb from creating symlinks\n",
    "os.environ[\"WANDB_DISABLE_SYMLINKS\"] = \"true\"\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def model_pipeline(cfg: dict):\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(project=\"pytorch-demo\", config=cfg):\n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "\n",
    "        # Execute only once to create the dataset\n",
    "        # generate_and_dump_dataset(config.root_dir, config.captions_file, config.transforms, cfg.DATA_LOCATION)\n",
    "\n",
    "        # Generate Dataset\n",
    "        dataset = make_dataset(config)\n",
    "\n",
    "        # Get the data loaders\n",
    "        train_loader, test_loader = make_dataloaders(config, dataset, 1)\n",
    "\n",
    "        # Generate vocab\n",
    "        vocab = dataset.vocab\n",
    "        config.vocab_size = len(vocab)\n",
    "\n",
    "        # Get the model\n",
    "        my_model = make_model(config, device)\n",
    "\n",
    "        # Define the loss and optimizer\n",
    "        criterion = get_criterion(config.criterion, vocab.stoi[\"<PAD>\"])\n",
    "        criterion.ignore_index=vocab.stoi[\"<PAD>\"]\n",
    "        \n",
    "        optimizer = get_optimizer(config.optimizer, my_model.parameters(), config.learning_rate)\n",
    "        \n",
    "        # Arrays to log data\n",
    "        train_loss_arr_epoch, test_loss_arr_epoch, acc_arr_epoch  = [], [], [] # Epoch-wise\n",
    "        train_loss_arr_batch, test_loss_arr_batch, acc_arr_batch = [], [], [] # Batch-wise\n",
    "        train_execution_times, test_execution_times = [], [] # Execution times\n",
    "\n",
    "        \n",
    "        for epoch in tqdm(range(1, config.epochs + 1)):\n",
    "            # Training\n",
    "            my_model.train()\n",
    "            train_loss_arr_aux, train_time = train(my_model, train_loader, criterion, optimizer, config, epoch)\n",
    "            my_model.eval()\n",
    "\n",
    "            # Testing\n",
    "            acc_arr_aux, test_loss_arr_aux, test_time = test(my_model, test_loader, criterion, vocab, config, device)\n",
    "\n",
    "            # Check how model performs\n",
    "            test_model_performance(my_model, test_loader, device, vocab, epoch, config)\n",
    "            \n",
    "            # Logging data for vizz\n",
    "            train_loss_arr_epoch.append(np.mean(train_loss_arr_aux)); test_loss_arr_epoch.append(np.mean(test_loss_arr_aux))\n",
    "            train_loss_arr_batch += train_loss_arr_aux; test_loss_arr_batch += test_loss_arr_aux\n",
    "            acc_arr_epoch.append(np.mean(acc_arr_aux)); acc_arr_batch += acc_arr_aux\n",
    "            train_execution_times.append(train_time); test_execution_times.append(test_time)\n",
    "\n",
    "            \n",
    "        if config.save:\n",
    "            export_data(train_loss_arr_epoch, test_loss_arr_epoch, acc_arr_epoch, train_execution_times, test_execution_times,\n",
    "                   train_loss_arr_batch, acc_arr_batch, test_loss_arr_batch, config)\n",
    "            \n",
    "            save_model(my_model, config, config.DATA_LOCATION+'/logs'+'/EncoderDecorder_model.pth')\n",
    "\n",
    "    return my_model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    wandb.login()\n",
    "\n",
    "    print(\"Using: \", device)\n",
    "\n",
    "    transforms = T.Compose([\n",
    "        T.Resize(226),\n",
    "        T.RandomCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "    DATA_LOCATION = '../data'\n",
    "\n",
    "    config = dict(\n",
    "        # Paths\n",
    "        root_dir=DATA_LOCATION+\"/Images\",\n",
    "        captions_file=DATA_LOCATION+\"/captions.txt\",\n",
    "        DATA_LOCATION=DATA_LOCATION,\n",
    "        save=True,\n",
    "\n",
    "        # Training data\n",
    "        epochs=1,\n",
    "        batch_size=50,\n",
    "        train_size=0.1,\n",
    "        \n",
    "        # Model data\n",
    "        optimizer='Adam',\n",
    "        criterion='CrossEntropy',\n",
    "        learning_rate=0.0001,\n",
    "        device=device,\n",
    "        encoder='ResNet50',\n",
    "        transforms=transforms,\n",
    "        embed_size=300,\n",
    "        attention_dim=256,\n",
    "        encoder_dim=2048,\n",
    "        decoder_dim=512,\n",
    "    )\n",
    "\n",
    "    model = model_pipeline(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58b76000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3333333333333335"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1,2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88038c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53a187c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Pau\\Desktop\\PycharmProjects\\xnap-project-matcad_grup_10\\SRC\\wandb\\run-20230530_154748-w7db1g0b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grup10/pytorch-demo/runs/w7db1g0b' target=\"_blank\">glamorous-frost-235</a></strong> to <a href='https://wandb.ai/grup10/pytorch-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grup10/pytorch-demo' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grup10/pytorch-demo/runs/w7db1g0b' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo/runs/w7db1g0b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d8c28aaaad4942bbdbb2805a276339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.017 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.066979…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glamorous-frost-235</strong> at: <a href='https://wandb.ai/grup10/pytorch-demo/runs/w7db1g0b' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo/runs/w7db1g0b</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230530_154748-w7db1g0b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'ignore_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Define the loss and optimizer\u001b[39;00m\n\u001b[0;32m     22\u001b[0m criterion \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mcriterion\n\u001b[1;32m---> 23\u001b[0m criterion\u001b[38;5;241m.\u001b[39mignore_index\u001b[38;5;241m=\u001b[39mvocab\u001b[38;5;241m.\u001b[39mstoi[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<PAD>\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     25\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39moptimizer\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mparms \u001b[38;5;241m=\u001b[39m my_model\u001b[38;5;241m.\u001b[39mparameters()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'ignore_index'"
     ]
    }
   ],
   "source": [
    "with wandb.init(project=\"pytorch-demo\", config=config):\n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "\n",
    "        # Execute only once to create the dataset\n",
    "        # generate_and_dump_dataset(config.root_dir, config.captions_file, config.transforms, cfg.DATA_LOCATION)\n",
    "\n",
    "        # Generate Dataset\n",
    "        dataset = make_dataset(config)\n",
    "\n",
    "        # Get the data loaders\n",
    "        train_loader, test_loader = make_dataloaders(config, dataset, 1)\n",
    "\n",
    "        # Generate vocab\n",
    "        vocab = dataset.vocab\n",
    "        config.vocab_size = len(vocab)\n",
    "\n",
    "        # Get the model\n",
    "        my_model = make_model(config, device)\n",
    "\n",
    "        # Define the loss and optimizer\n",
    "        criterion = config.criterion\n",
    "        criterion.ignore_index=vocab.stoi[\"<PAD>\"]\n",
    "        \n",
    "        optimizer = config.optimizer\n",
    "        optimizer.parms = my_model.parameters()\n",
    "        optimizer.lr = config.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecee412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d24d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb6438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81575bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit.ignore_index = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a83bba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a0fdc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(params=[torch.zeros([4,2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c7c9250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.optim.adam.Adam"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54f6c010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Pau\\Desktop\\PycharmProjects\\xnap-project-matcad_grup_10\\SRC\\wandb\\run-20230530_131140-t9rs5a0n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grup10/pytorch-demo/runs/t9rs5a0n' target=\"_blank\">deep-violet-228</a></strong> to <a href='https://wandb.ai/grup10/pytorch-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grup10/pytorch-demo' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grup10/pytorch-demo/runs/t9rs5a0n' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo/runs/t9rs5a0n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deep-violet-228</strong> at: <a href='https://wandb.ai/grup10/pytorch-demo/runs/t9rs5a0n' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo/runs/t9rs5a0n</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230530_131140-t9rs5a0n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=\"pytorch-demo\", config=config):\n",
    "    config = wandb.config\n",
    "\n",
    "    # Generate Dataset\n",
    "    dataset = make_dataset(config)\n",
    "\n",
    "    # make the data_loaders, and optimizer\n",
    "    #train_loader, test_loader = make_dataloaders(config, dataset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f3ae806",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = preprocess_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1937fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[[-0.9019, -0.1315, -0.2341,  ..., -1.3301, -1.5527, -1.2783],\n",
       "           [-1.0215, -0.1829, -0.2170,  ..., -1.4502, -1.5869, -1.6895],\n",
       "           [-1.0566, -0.1656, -0.2000,  ..., -1.6211, -1.5527, -1.6387],\n",
       "           ...,\n",
       "           [ 1.6670,  1.4951,  0.4680,  ...,  1.5293,  0.6733,  0.7246],\n",
       "           [ 0.8789,  0.1083,  0.0056,  ...,  1.4951,  0.6733,  0.6904],\n",
       "           [ 0.6904,  1.5469,  0.9644,  ...,  1.4951,  0.7075,  0.6904]],\n",
       "  \n",
       "          [[-0.7925,  0.0301, -0.0049,  ..., -1.2832, -1.5107, -0.9502],\n",
       "           [-0.9678, -0.0224,  0.0476,  ..., -1.4229, -1.5635, -1.5801],\n",
       "           [-1.0029, -0.0049,  0.0301,  ..., -1.5459, -1.4404, -1.5459],\n",
       "           ...,\n",
       "           [ 1.2207,  0.7656, -0.6177,  ...,  1.8506,  1.2031,  1.1855],\n",
       "           [-0.2500, -0.4775, -0.4602,  ...,  1.8330,  1.2207,  1.2031],\n",
       "           [ 0.0476,  1.0459,  0.3103,  ...,  1.8154,  1.2031,  1.1855]],\n",
       "  \n",
       "          [[-0.6021,  0.1302,  0.0779,  ..., -1.2812, -1.4902, -1.2637],\n",
       "           [-0.6890,  0.0779,  0.0605,  ..., -1.4033, -1.4902, -1.5781],\n",
       "           [-0.7935,  0.0953,  0.1302,  ..., -1.5254, -1.4033, -1.5781],\n",
       "           ...,\n",
       "           [-0.2358, -0.4275, -1.2295,  ...,  2.3086,  1.8906,  1.7861],\n",
       "           [-1.0547, -1.0898, -1.0898,  ...,  2.2910,  1.8906,  1.7686],\n",
       "           [-0.6714, -0.2358, -0.7759,  ...,  2.2734,  1.8555,  1.7510]]],\n",
       "         dtype=torch.float16),\n",
       "  [tensor([  1,   4,  28,   8,   4, 195, 151,  17,  32,  67,   4, 353,  11, 711,\n",
       "             8,  24,   3, 496,   5,   2]),\n",
       "   tensor([  1,   4,   7, 316,  76,   4, 157,  74,   5,   2]),\n",
       "   tensor([   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2]),\n",
       "   tensor([   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2]),\n",
       "   tensor([  1,   4,   9,   7,   8,   4, 195, 151, 316,  76,   4, 157,   3,   5,\n",
       "             2])]],\n",
       " [tensor([[[-1.4160, -1.4160, -1.4160,  ..., -1.1758, -1.2959, -1.2959],\n",
       "           [-1.4326, -1.4326, -1.4160,  ..., -1.3301, -1.3135, -1.2441],\n",
       "           [-1.4502, -1.4326, -1.4502,  ..., -1.5527, -1.4844, -1.2275],\n",
       "           ...,\n",
       "           [ 0.1940,  0.1255,  0.3652,  ..., -0.4397, -0.4739, -0.2341],\n",
       "           [ 0.1426,  0.2281,  0.1768,  ..., -0.1486, -0.1486, -0.2000],\n",
       "           [ 0.2111,  0.0398, -0.1656,  ..., -0.1143, -0.3540, -0.4910]],\n",
       "  \n",
       "          [[-1.3525, -1.3525, -1.3525,  ..., -0.6177, -0.7925, -0.8804],\n",
       "           [-1.3701, -1.3701, -1.3525,  ..., -0.8804, -0.8804, -0.8452],\n",
       "           [-1.3877, -1.3701, -1.3877,  ..., -1.2129, -1.1426, -0.8804],\n",
       "           ...,\n",
       "           [ 0.2927,  0.2227,  0.4502,  ..., -0.3550, -0.3901, -0.1449],\n",
       "           [ 0.2052,  0.3276,  0.2578,  ..., -0.0399, -0.0399, -0.0924],\n",
       "           [ 0.3103,  0.1876, -0.0399,  ..., -0.0049, -0.2676, -0.3726]],\n",
       "  \n",
       "          [[-1.1074, -1.1074, -1.1074,  ..., -1.1592, -1.2812, -1.3164],\n",
       "           [-1.1250, -1.1250, -1.1074,  ..., -1.2119, -1.1943, -1.2471],\n",
       "           [-1.1426, -1.1250, -1.1426,  ..., -1.2988, -1.2295, -1.1943],\n",
       "           ...,\n",
       "           [ 0.5835,  0.5137,  0.7056,  ...,  0.0779,  0.0082,  0.2522],\n",
       "           [ 0.5312,  0.6528,  0.5483,  ...,  0.2871,  0.3044,  0.2871],\n",
       "           [ 0.6006,  0.4961,  0.2695,  ...,  0.3394,  0.1128,  0.0256]]],\n",
       "         dtype=torch.float16),\n",
       "  [tensor([  1,   4,  20,   6,  16,   4, 680,   6,  34, 694,   2]),\n",
       "   tensor([  1,   4,  20,   6,  16,   4, 898, 116, 239,   6,  41,  12, 106, 107,\n",
       "            13,  10, 177,   5,   2]),\n",
       "   tensor([  1,   4,  20,   6,  16,   4,  21,   6,  12,  30, 930,  34, 837,  19,\n",
       "           106, 107,   8,  10,  65,   5,   2]),\n",
       "   tensor([   1,   50,   51,   11,  321, 1904,   78,   19,  106,  107,   13,   10,\n",
       "            177,    5,    2]),\n",
       "   tensor([  1,  50,  51,  13, 592, 622, 544, 106, 107,   5,   2])]],\n",
       " [tensor([[[ 1.4951,  1.5127,  1.5127,  ...,  1.7012,  1.7178,  1.7012],\n",
       "           [ 1.4443,  1.4609,  1.4609,  ...,  1.7178,  1.7178,  1.7012],\n",
       "           [ 1.3926,  1.4268,  1.4443,  ...,  1.7178,  1.7012,  1.6836],\n",
       "           ...,\n",
       "           [-0.5596, -1.0908, -1.0732,  ..., -0.5938, -0.5254, -0.3198],\n",
       "           [-0.2000, -0.9707, -1.0215,  ..., -0.4568, -0.6792, -0.2341],\n",
       "           [-0.5767, -0.5767, -0.9878,  ..., -0.4397, -0.8335, -0.1829]],\n",
       "  \n",
       "          [[ 1.7812,  1.7979,  1.7979,  ...,  1.9736,  1.9912,  1.9912],\n",
       "           [ 1.7285,  1.7461,  1.7461,  ...,  1.9912,  1.9912,  2.0254],\n",
       "           [ 1.7109,  1.7109,  1.7285,  ...,  1.9912,  1.9912,  2.0078],\n",
       "           ...,\n",
       "           [ 0.0476, -0.5479, -0.4951,  ..., -0.0224, -0.0049,  0.2052],\n",
       "           [ 0.2227, -0.4951, -0.3376,  ...,  0.1702, -0.0750,  0.2751],\n",
       "           [-0.1274, -0.0750, -0.3726,  ...,  0.0476, -0.1799,  0.3452]],\n",
       "  \n",
       "          [[ 1.8730,  1.8906,  1.8906,  ...,  2.1523,  2.1699,  2.1699],\n",
       "           [ 1.8213,  1.8379,  1.8379,  ...,  2.1699,  2.1523,  2.1523],\n",
       "           [ 1.7686,  1.7861,  1.8037,  ...,  2.1699,  2.1699,  2.1699],\n",
       "           ...,\n",
       "           [-0.7588, -1.2637, -1.0723,  ..., -1.1426, -1.0205, -1.0029],\n",
       "           [-0.5845, -1.1592, -1.1943,  ..., -0.7588, -1.0723, -0.6890],\n",
       "           [-0.8633, -0.9331, -1.1426,  ..., -0.9678, -1.3691, -0.5146]]],\n",
       "         dtype=torch.float16),\n",
       "  [tensor([   1,    4,    9,    7,  114,    8, 1447,   77,    8,   23,   11,    4,\n",
       "            325,  643,   12,  104,  229,    8,    4, 1301,    5,    2]),\n",
       "   tensor([  1,   4,   9,   7,  17,  46,   8,  23,  11,   4,  53, 325, 643,   5,\n",
       "             2]),\n",
       "   tensor([   1,    4,   85,    7,    8,   10,   22,   92,   12,    3,    8,   23,\n",
       "             11,    4,   21, 2306,   12,    4,  643,   13,   64,    5,    2]),\n",
       "   tensor([  1, 204,  17,   4,   7,  12,  91,  46,   8,  23,  11,   4, 643, 176,\n",
       "             5,   2]),\n",
       "   tensor([  1,  61,   7,  12,  91, 176,  70,   8,  10,  22,   5,   2])]]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56feef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e193e17f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d5df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c904e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f4ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_iter = iter(train_loader)\n",
    "img, cap = next(my_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdf08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "771d5be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da4571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "852f024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2, cap2 = next(my_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4458442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7d6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8d92b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f300718",
   "metadata": {},
   "outputs": [],
   "source": [
    "image,captions = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99653d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, captions = image.to(device), captions.to(device)\n",
    "\n",
    "# Zero the gradients.\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Feed forward\n",
    "outputs, attentions = my_model(image.to(torch.float32), captions)\n",
    "\n",
    "# Calculate the batch loss.\n",
    "targets = captions[:, 1:]\n",
    "loss = criterion(outputs.view(-1, config.vocab_size), targets.reshape(-1))\n",
    "\n",
    "# Backward pass.\n",
    "loss.backward()\n",
    "\n",
    "# Update the parameters in the optimizer.\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69795396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0419, -0.0200, -0.0398,  ..., -0.0310,  0.0729,  0.0062],\n",
       "        [ 0.1156, -0.0232, -0.1058,  ...,  0.0588,  0.0166, -0.1509],\n",
       "        [ 0.0336,  0.0681, -0.1028,  ...,  0.0521,  0.0040, -0.1283],\n",
       "        ...,\n",
       "        [-0.2936,  0.1309,  0.0571,  ..., -0.1252,  0.2291, -0.0856],\n",
       "        [-0.2734,  0.2516, -0.0050,  ...,  0.0603, -0.0179, -0.0015],\n",
       "        [-0.2988,  0.1344, -0.0523,  ...,  0.0208, -0.0471,  0.0206]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.view(-1, config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac22fef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 20])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions[:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41efcc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0419, -0.0200, -0.0398,  ..., -0.0310,  0.0729,  0.0062],\n",
       "        [ 0.1156, -0.0232, -0.1058,  ...,  0.0588,  0.0166, -0.1509],\n",
       "        [ 0.0336,  0.0681, -0.1028,  ...,  0.0521,  0.0040, -0.1283],\n",
       "        ...,\n",
       "        [-0.2936,  0.1309,  0.0571,  ..., -0.1252,  0.2291, -0.0856],\n",
       "        [-0.2734,  0.2516, -0.0050,  ...,  0.0603, -0.0179, -0.0015],\n",
       "        [-0.2988,  0.1344, -0.0523,  ...,  0.0208, -0.0471,  0.0206]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.view(-1, config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed23570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training and track with wandb\n",
    "example_ct = 0  # number of examples seen\n",
    "batch_ct = 0\n",
    "\n",
    "loss_arr_batch = []  # Losses of the batches\n",
    "\n",
    "for idx, (image, captions) in enumerate(iter(data_loader)):\n",
    "\n",
    "    loss = train_batch(image.to(torch.float32), captions, model, config.vocab_size, optimizer, criterion, device=config.device)\n",
    "    example_ct += len(image)\n",
    "    batch_ct += 1\n",
    "\n",
    "    loss_arr_batch.append(loss.tolist())\n",
    "\n",
    "    # Report metrics every 1th batch\n",
    "    if ((batch_ct + 1) % 1) == 0 and verbatim:\n",
    "        train_log(loss, example_ct, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba8be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41984f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b5b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d28def3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71b03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977c40f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc53be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad055988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e516d6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.296547889709473"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "my_iter = iter(train_loader)\n",
    "t1 = time.time()\n",
    "t0-t1\n",
    "# bs 32 nw all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae5e495",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = next(my_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d98d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1,   4,  28,   8,   4, 195, 151,  17,  32,  67,   4, 353,  11, 711,\n",
       "          8,  24,   3, 496,   5,   2], dtype=torch.int16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.data[0//5][1][0%5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16e378e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]], dtype=torch.int16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb7d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70173f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e5986ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.776714086532593"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "my_iter = iter(train_loader)\n",
    "t1 = time.time()\n",
    "t0-t1\n",
    "# bs 500 nw 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de2c3f69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for a, b in my_iter:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2e5435a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "('{} cannot be pickled', '_MultiProcessingDataLoaderIter')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m iter_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xnap-example\\lib\\copy.py:161\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    159\u001b[0m reductor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce_ex__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reductor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[43mreductor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:657\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__getstate__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getstate__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;66;03m# TODO: add limited pickling support for sharing an iterator\u001b[39;00m\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;66;03m# across multiple threads for HOGWILD.\u001b[39;00m\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;66;03m# Probably the best way to do this is by moving the sample pushing\u001b[39;00m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;66;03m# to a separate thread and then just sharing the data queue\u001b[39;00m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;66;03m# but signalling the end is tricky without a non-blocking API\u001b[39;00m\n\u001b[1;32m--> 657\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m cannot be pickled\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: ('{} cannot be pickled', '_MultiProcessingDataLoaderIter')"
     ]
    }
   ],
   "source": [
    "iter_2 = deepcopy(my_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eef0da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xnap-example",
   "language": "python",
   "name": "xnap-example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
