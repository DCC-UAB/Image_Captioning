{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a69d37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:  cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce5c88479584a359ea09a151bbf9431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Pau\\Desktop\\PycharmProjects\\xnap-project-matcad_grup_10\\SRC\\wandb\\run-20230601_120651-7b7u47t9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grup10/pytorch-demo/runs/7b7u47t9' target=\"_blank\">comic-dragon-261</a></strong> to <a href='https://wandb.ai/grup10/pytorch-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grup10/pytorch-demo' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grup10/pytorch-demo/runs/7b7u47t9' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo/runs/7b7u47t9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG Optimizer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6b6e48e76f495cafebfd8f08600f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 00050 examples: 7.994\n",
      "Loss after 00100 examples: 7.970\n",
      "Loss after 00150 examples: 7.933\n",
      "Loss after 00200 examples: 7.891\n",
      "Loss after 00250 examples: 7.846\n",
      "Loss after 00300 examples: 7.805\n",
      "Loss after 00350 examples: 7.804\n",
      "Loss after 00400 examples: 7.753\n",
      "Loss after 00450 examples: 7.698\n",
      "Loss after 00500 examples: 7.651\n",
      "Loss after 00550 examples: 7.568\n",
      "Loss after 00600 examples: 7.502\n",
      "Loss after 00650 examples: 7.389\n",
      "Loss after 00700 examples: 7.377\n",
      "Loss after 00750 examples: 7.325\n",
      "Loss after 00800 examples: 7.236\n",
      "Loss after 00850 examples: 7.096\n",
      "Loss after 00900 examples: 7.062\n",
      "Loss after 00950 examples: 6.986\n",
      "Loss after 01000 examples: 6.871\n",
      "Loss after 01050 examples: 6.802\n",
      "Loss after 01100 examples: 6.697\n",
      "Loss after 01150 examples: 6.621\n",
      "Loss after 01200 examples: 6.672\n",
      "Loss after 01250 examples: 6.459\n",
      "Loss after 01300 examples: 6.388\n",
      "Loss after 01350 examples: 6.323\n",
      "Loss after 01400 examples: 6.276\n",
      "Loss after 01450 examples: 6.164\n",
      "Loss after 01500 examples: 6.123\n",
      "Loss after 01550 examples: 5.962\n",
      "Loss after 01600 examples: 5.943\n",
      "Loss after 01650 examples: 5.762\n",
      "Loss after 01700 examples: 5.905\n",
      "Loss after 01750 examples: 5.588\n",
      "Loss after 01800 examples: 5.827\n",
      "Loss after 01850 examples: 5.555\n",
      "Loss after 01900 examples: 5.680\n",
      "Loss after 01950 examples: 5.592\n",
      "Loss after 02000 examples: 5.530\n",
      "Loss after 02050 examples: 5.445\n",
      "Loss after 02100 examples: 5.470\n",
      "Loss after 02150 examples: 5.465\n",
      "Loss after 02200 examples: 5.327\n",
      "Loss after 02250 examples: 5.328\n",
      "Loss after 02300 examples: 5.363\n",
      "Loss after 02350 examples: 5.243\n",
      "Loss after 02400 examples: 5.192\n",
      "Loss after 02450 examples: 5.233\n",
      "Loss after 02500 examples: 5.130\n",
      "Loss after 02550 examples: 5.044\n",
      "Loss after 02600 examples: 5.208\n",
      "Loss after 02650 examples: 5.219\n",
      "Loss after 02700 examples: 5.116\n",
      "Loss after 02750 examples: 4.982\n",
      "Loss after 02800 examples: 5.058\n",
      "Loss after 02850 examples: 5.153\n",
      "Loss after 02900 examples: 5.074\n",
      "Loss after 02950 examples: 4.966\n",
      "Loss after 03000 examples: 5.053\n",
      "Loss after 03050 examples: 5.085\n",
      "Loss after 03100 examples: 4.860\n",
      "Loss after 03150 examples: 4.983\n",
      "Loss after 03200 examples: 5.005\n",
      "Loss after 03250 examples: 4.893\n",
      "Loss after 03300 examples: 4.910\n",
      "Loss after 03350 examples: 4.873\n",
      "Loss after 03400 examples: 5.037\n",
      "Loss after 03450 examples: 4.874\n",
      "Loss after 03500 examples: 4.810\n",
      "Loss after 03550 examples: 4.752\n",
      "Loss after 03600 examples: 4.918\n",
      "Loss after 03650 examples: 4.887\n",
      "Loss after 03700 examples: 4.897\n",
      "Loss after 03750 examples: 4.892\n",
      "Loss after 03800 examples: 4.808\n",
      "Loss after 03850 examples: 4.889\n",
      "Loss after 03900 examples: 4.782\n",
      "Loss after 03950 examples: 4.782\n",
      "Loss after 04000 examples: 4.856\n",
      "Loss after 04045 examples: 4.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pau\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\Pau\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 24 \n",
      "Acc_score =  5.535069030704902e-155\n",
      "Loss: 5.556129455566406\n",
      "Batch: 49 \n",
      "Acc_score =  7.657404561915943e-155\n",
      "Loss: 5.191032409667969\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>████▇▇▇▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>4.89107</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comic-dragon-261</strong> at: <a href='https://wandb.ai/grup10/pytorch-demo/runs/7b7u47t9' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo/runs/7b7u47t9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230601_120651-7b7u47t9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 175\u001b[0m\n\u001b[0;32m    147\u001b[0m DATA_LOCATION \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    149\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;66;03m# Paths\u001b[39;00m\n\u001b[0;32m    151\u001b[0m     root_dir\u001b[38;5;241m=\u001b[39mDATA_LOCATION\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Images\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    172\u001b[0m     momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m\n\u001b[0;32m    173\u001b[0m )\n\u001b[1;32m--> 175\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 114\u001b[0m, in \u001b[0;36mmodel_pipeline\u001b[1;34m(cfg)\u001b[0m\n\u001b[0;32m    111\u001b[0m my_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Testing\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m acc_arr_aux, test_loss_arr_aux, test_time \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Check how model performs\u001b[39;00m\n\u001b[0;32m    117\u001b[0m test_model_performance(my_model, test_loader, device, vocab, epoch, config)\n",
      "File \u001b[1;32m~\\Desktop\\PycharmProjects\\xnap-project-matcad_grup_10\\SRC\\test.py:19\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(model, test_loader, criterion, vocab, config, device, verbatim)\u001b[0m\n\u001b[0;32m     16\u001b[0m images, captions \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32), captions\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Calculating loss\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m outputs, attentions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m targets \u001b[38;5;241m=\u001b[39m captions[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, config\u001b[38;5;241m.\u001b[39mvocab_size), targets\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\torch\\nn\\modules\\module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1536\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1538\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1540\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m   1541\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1542\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[0;32m   1543\u001b[0m     ):\n",
      "File \u001b[1;32m~\\Desktop\\PycharmProjects\\xnap-project-matcad_grup_10\\SRC\\models\\models.py:181\u001b[0m, in \u001b[0;36mEncoderDecoder.forward\u001b[1;34m(self, images, captions)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, captions):\n\u001b[1;32m--> 181\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(features, captions)\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Desktop\\PycharmProjects\\xnap-project-matcad_grup_10\\SRC\\models\\models.py:30\u001b[0m, in \u001b[0;36mEncoderCNN.forward\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, images):\n\u001b[1;32m---> 30\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmy_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size,2048,7,7)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (batch_size,7,7,2048)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mview(features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# (batch_size,49,2048)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\torchvision\\models\\resnet.py:150\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    147\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m    148\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m--> 150\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[0;32m    152\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Performance and visualization\n",
    "import os\n",
    "import wandb\n",
    "import multiprocessing\n",
    "\n",
    "# Data manipulation packages\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import random\n",
    "\n",
    "# Own packages\n",
    "from train import *\n",
    "from test import *\n",
    "from utils.utils import *\n",
    "from models.models import *\n",
    "\n",
    "\n",
    "# Global variables\n",
    "global device\n",
    "\n",
    "# Environment variables (different for each computer)\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\" # Setting CUDA ALLOC split size to 256 to avoid running out of memory\n",
    "os.environ[\"WANDB_DISABLE_SYMLINKS\"] = \"true\" # Stopping wandb from creating symlinks\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def model_pipeline(cfg: dict):\n",
    "    \"\"\"\n",
    "    Main loop containing the train-test tasks. All parameter information is included on the config dictionary.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    cfg: dictionary.\n",
    "    \tContains all the specific parameters to execute the pipeline in string format.\n",
    "        # Paths\n",
    "        root_dir: Directory where the images are stored.\n",
    "        captions_file: Directory where the captions are stored.\n",
    "        DATA_LOCATION: Father directory of the images and captions. Where all the data will be storage.\n",
    "        save: Boolean, if True then execution logs will be storaged.\n",
    "\n",
    "        # Training data\n",
    "        epochs: Number of epoch.\n",
    "        batch_size: Batch size to split the data.\n",
    "        train_size: Train size (in percentage).\n",
    "        \n",
    "        # Model data\n",
    "        optimizer: Name of the optimizer. 'Adam', 'Adagrad', 'SGD'.\n",
    "        criterion: Name of the criterion used. 'CrossEntropy', 'MSE'\n",
    "        learning_rate: Learning rate used for the optimizer.\n",
    "        momentum: Momentum used for the optimizer if required.\n",
    "        device: Device used. 'CPU' or 'cuda:0'.\n",
    "        encoder: Pre-trained net used for encoding the data. 'ResNet50', 'ResNet152', 'googleNet', 'VGG'.\n",
    "        transforms: Transforms applied to the images.\n",
    "        embed_size: Embedding size. Recomended: 300\n",
    "        attention_dim: Dimension for the attention. Recomended: 256.\n",
    "        encoder_dim: Dimension for the encoder. Depends of the encoder chosen. Recomended: 2048 (ResNet). 512 (VGG). 1024 (GoogleNet)\n",
    "        decoder_dim: Dimension for the decoder. Recomended: 512.\n",
    "        \n",
    "    Returns\n",
    "    ---------\n",
    "    Trained Model.\n",
    "    \"\"\"\n",
    "    \n",
    "    with wandb.init(project=\"pytorch-demo\", config=cfg): # Starting wandb\n",
    "        config = wandb.config # access all HPs through wandb.config, so logging matches execution!\n",
    "\n",
    "        # Execute only once to create the dataset\n",
    "        # generate_and_dump_dataset(config.root_dir, config.captions_file, config.transforms, cfg.DATA_LOCATION)\n",
    "\n",
    "        # Generate Dataset\n",
    "        dataset = make_dataset(config)\n",
    "\n",
    "        # Get the data loaders\n",
    "        train_loader, test_loader = make_dataloaders(config, dataset, 1)\n",
    "\n",
    "        # Extract vocab\n",
    "        vocab = dataset.vocab\n",
    "        config.vocab_size = len(vocab)\n",
    "\n",
    "        # Get the model\n",
    "        my_model = make_model(config, device)\n",
    "\n",
    "        # Define the loss and optimizer\n",
    "        criterion = get_criterion(config.criterion, vocab.stoi[\"<PAD>\"])\n",
    "        criterion.ignore_index=vocab.stoi[\"<PAD>\"]\n",
    "        \n",
    "        optimizer = get_optimizer(config.optimizer, my_model.parameters(), config.learning_rate, config.momentum)\n",
    "        \n",
    "        # Arrays to log data\n",
    "        train_loss_arr_epoch, test_loss_arr_epoch, acc_arr_epoch  = [], [], [] # Epoch-wise\n",
    "        train_loss_arr_batch, test_loss_arr_batch, acc_arr_batch = [], [], [] # Batch-wise\n",
    "        train_execution_times, test_execution_times = [], [] # Execution times\n",
    "\n",
    "        # Main loop\n",
    "        for epoch in tqdm(range(1, config.epochs + 1)):\n",
    "            # Training\n",
    "            my_model.train()\n",
    "            train_loss_arr_aux, train_time = train(my_model, train_loader, criterion, optimizer, config, epoch)\n",
    "            my_model.eval()\n",
    "\n",
    "            # Testing\n",
    "            acc_arr_aux, test_loss_arr_aux, test_time = test(my_model, test_loader, criterion, vocab, config, device)\n",
    "\n",
    "            # Check how model performs\n",
    "            test_model_performance(my_model, test_loader, device, vocab, epoch, config)\n",
    "            \n",
    "            # Logging data for vizz\n",
    "            train_loss_arr_epoch.append(np.mean(train_loss_arr_aux)); test_loss_arr_epoch.append(np.mean(test_loss_arr_aux))\n",
    "            train_loss_arr_batch += train_loss_arr_aux; test_loss_arr_batch += test_loss_arr_aux\n",
    "            acc_arr_epoch.append(np.mean(acc_arr_aux)); acc_arr_batch += acc_arr_aux\n",
    "            train_execution_times.append(train_time); test_execution_times.append(test_time)\n",
    "\n",
    "        # Saving the logs\n",
    "        if config.save:\n",
    "            export_data(train_loss_arr_epoch, test_loss_arr_epoch, acc_arr_epoch, train_execution_times, test_execution_times,\n",
    "                   train_loss_arr_batch, acc_arr_batch, test_loss_arr_batch, config)\n",
    "            \n",
    "            save_model(my_model, config, config.DATA_LOCATION+'/logs'+'/EncoderDecorder_model.pth')\n",
    "\n",
    "    return my_model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    wandb.login()\n",
    "\n",
    "    print(\"Using: \", device)\n",
    "\n",
    "    transforms = T.Compose([\n",
    "        T.Resize(226),\n",
    "        T.RandomCrop(224),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "    DATA_LOCATION = '../data'\n",
    "\n",
    "    config = dict(\n",
    "        # Paths\n",
    "        root_dir=DATA_LOCATION+\"/Images\",\n",
    "        captions_file=DATA_LOCATION+\"/captions.txt\",\n",
    "        DATA_LOCATION=DATA_LOCATION,\n",
    "        save=True,\n",
    "\n",
    "        # Training data\n",
    "        epochs=1,\n",
    "        batch_size=50,\n",
    "        train_size=0.1,\n",
    "        \n",
    "        # Model data\n",
    "        optimizer='SDG',\n",
    "        criterion='CrossEntropy',\n",
    "        learning_rate=0.0001,\n",
    "        device=device,\n",
    "        encoder='ResNet50',\n",
    "        transforms=transforms,\n",
    "        embed_size=300,\n",
    "        attention_dim=256,\n",
    "        encoder_dim=2048,\n",
    "        decoder_dim=512,\n",
    "        momentum=0.9\n",
    "    )\n",
    "\n",
    "    model = model_pipeline(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62754c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3333333333333335"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1,2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88d23c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4222e597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Pau\\Desktop\\PycharmProjects\\xnap-project-matcad_grup_10\\SRC\\wandb\\run-20230530_154748-w7db1g0b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grup10/pytorch-demo/runs/w7db1g0b' target=\"_blank\">glamorous-frost-235</a></strong> to <a href='https://wandb.ai/grup10/pytorch-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grup10/pytorch-demo' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grup10/pytorch-demo/runs/w7db1g0b' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo/runs/w7db1g0b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d8c28aaaad4942bbdbb2805a276339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.017 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.066979…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glamorous-frost-235</strong> at: <a href='https://wandb.ai/grup10/pytorch-demo/runs/w7db1g0b' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo/runs/w7db1g0b</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230530_154748-w7db1g0b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'ignore_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Define the loss and optimizer\u001b[39;00m\n\u001b[0;32m     22\u001b[0m criterion \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mcriterion\n\u001b[1;32m---> 23\u001b[0m criterion\u001b[38;5;241m.\u001b[39mignore_index\u001b[38;5;241m=\u001b[39mvocab\u001b[38;5;241m.\u001b[39mstoi[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<PAD>\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     25\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39moptimizer\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mparms \u001b[38;5;241m=\u001b[39m my_model\u001b[38;5;241m.\u001b[39mparameters()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'ignore_index'"
     ]
    }
   ],
   "source": [
    "with wandb.init(project=\"pytorch-demo\", config=config):\n",
    "        # access all HPs through wandb.config, so logging matches execution!\n",
    "        config = wandb.config\n",
    "\n",
    "        # Execute only once to create the dataset\n",
    "        # generate_and_dump_dataset(config.root_dir, config.captions_file, config.transforms, cfg.DATA_LOCATION)\n",
    "\n",
    "        # Generate Dataset\n",
    "        dataset = make_dataset(config)\n",
    "\n",
    "        # Get the data loaders\n",
    "        train_loader, test_loader = make_dataloaders(config, dataset, 1)\n",
    "\n",
    "        # Generate vocab\n",
    "        vocab = dataset.vocab\n",
    "        config.vocab_size = len(vocab)\n",
    "\n",
    "        # Get the model\n",
    "        my_model = make_model(config, device)\n",
    "\n",
    "        # Define the loss and optimizer\n",
    "        criterion = config.criterion\n",
    "        criterion.ignore_index=vocab.stoi[\"<PAD>\"]\n",
    "        \n",
    "        optimizer = config.optimizer\n",
    "        optimizer.parms = my_model.parameters()\n",
    "        optimizer.lr = config.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e1a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8589dbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac854db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681eee3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e2142fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit.ignore_index = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6757087",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a0fdc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(params=[torch.zeros([4,2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19475b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.optim.adam.Adam"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54f6c010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Pau\\Desktop\\PycharmProjects\\xnap-project-matcad_grup_10\\SRC\\wandb\\run-20230530_131140-t9rs5a0n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/grup10/pytorch-demo/runs/t9rs5a0n' target=\"_blank\">deep-violet-228</a></strong> to <a href='https://wandb.ai/grup10/pytorch-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/grup10/pytorch-demo' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/grup10/pytorch-demo/runs/t9rs5a0n' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo/runs/t9rs5a0n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">deep-violet-228</strong> at: <a href='https://wandb.ai/grup10/pytorch-demo/runs/t9rs5a0n' target=\"_blank\">https://wandb.ai/grup10/pytorch-demo/runs/t9rs5a0n</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230530_131140-t9rs5a0n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=\"pytorch-demo\", config=config):\n",
    "    config = wandb.config\n",
    "\n",
    "    # Generate Dataset\n",
    "    dataset = make_dataset(config)\n",
    "\n",
    "    # make the data_loaders, and optimizer\n",
    "    #train_loader, test_loader = make_dataloaders(config, dataset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6cdd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = preprocess_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b72e5bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[[-0.9019, -0.1315, -0.2341,  ..., -1.3301, -1.5527, -1.2783],\n",
       "           [-1.0215, -0.1829, -0.2170,  ..., -1.4502, -1.5869, -1.6895],\n",
       "           [-1.0566, -0.1656, -0.2000,  ..., -1.6211, -1.5527, -1.6387],\n",
       "           ...,\n",
       "           [ 1.6670,  1.4951,  0.4680,  ...,  1.5293,  0.6733,  0.7246],\n",
       "           [ 0.8789,  0.1083,  0.0056,  ...,  1.4951,  0.6733,  0.6904],\n",
       "           [ 0.6904,  1.5469,  0.9644,  ...,  1.4951,  0.7075,  0.6904]],\n",
       "  \n",
       "          [[-0.7925,  0.0301, -0.0049,  ..., -1.2832, -1.5107, -0.9502],\n",
       "           [-0.9678, -0.0224,  0.0476,  ..., -1.4229, -1.5635, -1.5801],\n",
       "           [-1.0029, -0.0049,  0.0301,  ..., -1.5459, -1.4404, -1.5459],\n",
       "           ...,\n",
       "           [ 1.2207,  0.7656, -0.6177,  ...,  1.8506,  1.2031,  1.1855],\n",
       "           [-0.2500, -0.4775, -0.4602,  ...,  1.8330,  1.2207,  1.2031],\n",
       "           [ 0.0476,  1.0459,  0.3103,  ...,  1.8154,  1.2031,  1.1855]],\n",
       "  \n",
       "          [[-0.6021,  0.1302,  0.0779,  ..., -1.2812, -1.4902, -1.2637],\n",
       "           [-0.6890,  0.0779,  0.0605,  ..., -1.4033, -1.4902, -1.5781],\n",
       "           [-0.7935,  0.0953,  0.1302,  ..., -1.5254, -1.4033, -1.5781],\n",
       "           ...,\n",
       "           [-0.2358, -0.4275, -1.2295,  ...,  2.3086,  1.8906,  1.7861],\n",
       "           [-1.0547, -1.0898, -1.0898,  ...,  2.2910,  1.8906,  1.7686],\n",
       "           [-0.6714, -0.2358, -0.7759,  ...,  2.2734,  1.8555,  1.7510]]],\n",
       "         dtype=torch.float16),\n",
       "  [tensor([  1,   4,  28,   8,   4, 195, 151,  17,  32,  67,   4, 353,  11, 711,\n",
       "             8,  24,   3, 496,   5,   2]),\n",
       "   tensor([  1,   4,   7, 316,  76,   4, 157,  74,   5,   2]),\n",
       "   tensor([   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2]),\n",
       "   tensor([   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2]),\n",
       "   tensor([  1,   4,   9,   7,   8,   4, 195, 151, 316,  76,   4, 157,   3,   5,\n",
       "             2])]],\n",
       " [tensor([[[-1.4160, -1.4160, -1.4160,  ..., -1.1758, -1.2959, -1.2959],\n",
       "           [-1.4326, -1.4326, -1.4160,  ..., -1.3301, -1.3135, -1.2441],\n",
       "           [-1.4502, -1.4326, -1.4502,  ..., -1.5527, -1.4844, -1.2275],\n",
       "           ...,\n",
       "           [ 0.1940,  0.1255,  0.3652,  ..., -0.4397, -0.4739, -0.2341],\n",
       "           [ 0.1426,  0.2281,  0.1768,  ..., -0.1486, -0.1486, -0.2000],\n",
       "           [ 0.2111,  0.0398, -0.1656,  ..., -0.1143, -0.3540, -0.4910]],\n",
       "  \n",
       "          [[-1.3525, -1.3525, -1.3525,  ..., -0.6177, -0.7925, -0.8804],\n",
       "           [-1.3701, -1.3701, -1.3525,  ..., -0.8804, -0.8804, -0.8452],\n",
       "           [-1.3877, -1.3701, -1.3877,  ..., -1.2129, -1.1426, -0.8804],\n",
       "           ...,\n",
       "           [ 0.2927,  0.2227,  0.4502,  ..., -0.3550, -0.3901, -0.1449],\n",
       "           [ 0.2052,  0.3276,  0.2578,  ..., -0.0399, -0.0399, -0.0924],\n",
       "           [ 0.3103,  0.1876, -0.0399,  ..., -0.0049, -0.2676, -0.3726]],\n",
       "  \n",
       "          [[-1.1074, -1.1074, -1.1074,  ..., -1.1592, -1.2812, -1.3164],\n",
       "           [-1.1250, -1.1250, -1.1074,  ..., -1.2119, -1.1943, -1.2471],\n",
       "           [-1.1426, -1.1250, -1.1426,  ..., -1.2988, -1.2295, -1.1943],\n",
       "           ...,\n",
       "           [ 0.5835,  0.5137,  0.7056,  ...,  0.0779,  0.0082,  0.2522],\n",
       "           [ 0.5312,  0.6528,  0.5483,  ...,  0.2871,  0.3044,  0.2871],\n",
       "           [ 0.6006,  0.4961,  0.2695,  ...,  0.3394,  0.1128,  0.0256]]],\n",
       "         dtype=torch.float16),\n",
       "  [tensor([  1,   4,  20,   6,  16,   4, 680,   6,  34, 694,   2]),\n",
       "   tensor([  1,   4,  20,   6,  16,   4, 898, 116, 239,   6,  41,  12, 106, 107,\n",
       "            13,  10, 177,   5,   2]),\n",
       "   tensor([  1,   4,  20,   6,  16,   4,  21,   6,  12,  30, 930,  34, 837,  19,\n",
       "           106, 107,   8,  10,  65,   5,   2]),\n",
       "   tensor([   1,   50,   51,   11,  321, 1904,   78,   19,  106,  107,   13,   10,\n",
       "            177,    5,    2]),\n",
       "   tensor([  1,  50,  51,  13, 592, 622, 544, 106, 107,   5,   2])]],\n",
       " [tensor([[[ 1.4951,  1.5127,  1.5127,  ...,  1.7012,  1.7178,  1.7012],\n",
       "           [ 1.4443,  1.4609,  1.4609,  ...,  1.7178,  1.7178,  1.7012],\n",
       "           [ 1.3926,  1.4268,  1.4443,  ...,  1.7178,  1.7012,  1.6836],\n",
       "           ...,\n",
       "           [-0.5596, -1.0908, -1.0732,  ..., -0.5938, -0.5254, -0.3198],\n",
       "           [-0.2000, -0.9707, -1.0215,  ..., -0.4568, -0.6792, -0.2341],\n",
       "           [-0.5767, -0.5767, -0.9878,  ..., -0.4397, -0.8335, -0.1829]],\n",
       "  \n",
       "          [[ 1.7812,  1.7979,  1.7979,  ...,  1.9736,  1.9912,  1.9912],\n",
       "           [ 1.7285,  1.7461,  1.7461,  ...,  1.9912,  1.9912,  2.0254],\n",
       "           [ 1.7109,  1.7109,  1.7285,  ...,  1.9912,  1.9912,  2.0078],\n",
       "           ...,\n",
       "           [ 0.0476, -0.5479, -0.4951,  ..., -0.0224, -0.0049,  0.2052],\n",
       "           [ 0.2227, -0.4951, -0.3376,  ...,  0.1702, -0.0750,  0.2751],\n",
       "           [-0.1274, -0.0750, -0.3726,  ...,  0.0476, -0.1799,  0.3452]],\n",
       "  \n",
       "          [[ 1.8730,  1.8906,  1.8906,  ...,  2.1523,  2.1699,  2.1699],\n",
       "           [ 1.8213,  1.8379,  1.8379,  ...,  2.1699,  2.1523,  2.1523],\n",
       "           [ 1.7686,  1.7861,  1.8037,  ...,  2.1699,  2.1699,  2.1699],\n",
       "           ...,\n",
       "           [-0.7588, -1.2637, -1.0723,  ..., -1.1426, -1.0205, -1.0029],\n",
       "           [-0.5845, -1.1592, -1.1943,  ..., -0.7588, -1.0723, -0.6890],\n",
       "           [-0.8633, -0.9331, -1.1426,  ..., -0.9678, -1.3691, -0.5146]]],\n",
       "         dtype=torch.float16),\n",
       "  [tensor([   1,    4,    9,    7,  114,    8, 1447,   77,    8,   23,   11,    4,\n",
       "            325,  643,   12,  104,  229,    8,    4, 1301,    5,    2]),\n",
       "   tensor([  1,   4,   9,   7,  17,  46,   8,  23,  11,   4,  53, 325, 643,   5,\n",
       "             2]),\n",
       "   tensor([   1,    4,   85,    7,    8,   10,   22,   92,   12,    3,    8,   23,\n",
       "             11,    4,   21, 2306,   12,    4,  643,   13,   64,    5,    2]),\n",
       "   tensor([  1, 204,  17,   4,   7,  12,  91,  46,   8,  23,  11,   4, 643, 176,\n",
       "             5,   2]),\n",
       "   tensor([  1,  61,   7,  12,  91, 176,  70,   8,  10,  22,   5,   2])]]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11483cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0fd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9cc584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db2742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d39e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_iter = iter(train_loader)\n",
    "img, cap = next(my_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ffbbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "681c34d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016640c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4702a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2, cap2 = next(my_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54c182b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67734e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ebcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f300718",
   "metadata": {},
   "outputs": [],
   "source": [
    "image,captions = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99653d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, captions = image.to(device), captions.to(device)\n",
    "\n",
    "# Zero the gradients.\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Feed forward\n",
    "outputs, attentions = my_model(image.to(torch.float32), captions)\n",
    "\n",
    "# Calculate the batch loss.\n",
    "targets = captions[:, 1:]\n",
    "loss = criterion(outputs.view(-1, config.vocab_size), targets.reshape(-1))\n",
    "\n",
    "# Backward pass.\n",
    "loss.backward()\n",
    "\n",
    "# Update the parameters in the optimizer.\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69795396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0419, -0.0200, -0.0398,  ..., -0.0310,  0.0729,  0.0062],\n",
       "        [ 0.1156, -0.0232, -0.1058,  ...,  0.0588,  0.0166, -0.1509],\n",
       "        [ 0.0336,  0.0681, -0.1028,  ...,  0.0521,  0.0040, -0.1283],\n",
       "        ...,\n",
       "        [-0.2936,  0.1309,  0.0571,  ..., -0.1252,  0.2291, -0.0856],\n",
       "        [-0.2734,  0.2516, -0.0050,  ...,  0.0603, -0.0179, -0.0015],\n",
       "        [-0.2988,  0.1344, -0.0523,  ...,  0.0208, -0.0471,  0.0206]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.view(-1, config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac22fef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 20])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions[:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41efcc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0419, -0.0200, -0.0398,  ..., -0.0310,  0.0729,  0.0062],\n",
       "        [ 0.1156, -0.0232, -0.1058,  ...,  0.0588,  0.0166, -0.1509],\n",
       "        [ 0.0336,  0.0681, -0.1028,  ...,  0.0521,  0.0040, -0.1283],\n",
       "        ...,\n",
       "        [-0.2936,  0.1309,  0.0571,  ..., -0.1252,  0.2291, -0.0856],\n",
       "        [-0.2734,  0.2516, -0.0050,  ...,  0.0603, -0.0179, -0.0015],\n",
       "        [-0.2988,  0.1344, -0.0523,  ...,  0.0208, -0.0471,  0.0206]],\n",
       "       device='cuda:0', grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.view(-1, config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed23570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training and track with wandb\n",
    "example_ct = 0  # number of examples seen\n",
    "batch_ct = 0\n",
    "\n",
    "loss_arr_batch = []  # Losses of the batches\n",
    "\n",
    "for idx, (image, captions) in enumerate(iter(data_loader)):\n",
    "\n",
    "    loss = train_batch(image.to(torch.float32), captions, model, config.vocab_size, optimizer, criterion, device=config.device)\n",
    "    example_ct += len(image)\n",
    "    batch_ct += 1\n",
    "\n",
    "    loss_arr_batch.append(loss.tolist())\n",
    "\n",
    "    # Report metrics every 1th batch\n",
    "    if ((batch_ct + 1) % 1) == 0 and verbatim:\n",
    "        train_log(loss, example_ct, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba8be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41984f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b5b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d28def3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71b03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977c40f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc53be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad055988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e516d6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.296547889709473"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "my_iter = iter(train_loader)\n",
    "t1 = time.time()\n",
    "t0-t1\n",
    "# bs 32 nw all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae5e495",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = next(my_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d98d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1,   4,  28,   8,   4, 195, 151,  17,  32,  67,   4, 353,  11, 711,\n",
       "          8,  24,   3, 496,   5,   2], dtype=torch.int16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.data[0//5][1][0%5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16e378e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,   28,    8,    4,  195,  151,   17,   32,   67,    4,  353,\n",
       "           11,  711,    8,   24,    3,  496,    5,    2],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,    8,    4,  195,  151,  316,   76,    4,  157,\n",
       "            3,    5,    2,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   76,    4,  157, 2409,    5,    2,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    9,    7,   32,   10,  711,   27,  104, 2409,    5,    2,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   1,    4,    7,  316,   76,    4,  157,   74,    5,    2,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]], dtype=torch.int16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb7d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70173f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e5986ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.776714086532593"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "my_iter = iter(train_loader)\n",
    "t1 = time.time()\n",
    "t0-t1\n",
    "# bs 500 nw 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de2c3f69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for a, b in my_iter:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2e5435a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "('{} cannot be pickled', '_MultiProcessingDataLoaderIter')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m iter_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xnap-example\\lib\\copy.py:161\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    159\u001b[0m reductor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce_ex__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reductor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     rv \u001b[38;5;241m=\u001b[39m \u001b[43mreductor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__reduce__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\xnap-example\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:657\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__getstate__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getstate__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    652\u001b[0m     \u001b[38;5;66;03m# TODO: add limited pickling support for sharing an iterator\u001b[39;00m\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;66;03m# across multiple threads for HOGWILD.\u001b[39;00m\n\u001b[0;32m    654\u001b[0m     \u001b[38;5;66;03m# Probably the best way to do this is by moving the sample pushing\u001b[39;00m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;66;03m# to a separate thread and then just sharing the data queue\u001b[39;00m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;66;03m# but signalling the end is tricky without a non-blocking API\u001b[39;00m\n\u001b[1;32m--> 657\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m cannot be pickled\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: ('{} cannot be pickled', '_MultiProcessingDataLoaderIter')"
     ]
    }
   ],
   "source": [
    "iter_2 = deepcopy(my_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eef0da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xnap-example",
   "language": "python",
   "name": "xnap-example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
